{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2b40258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json, pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c485136c",
   "metadata": {},
   "source": [
    "# Steam Game Recommendation System (AI Prototype)\n",
    "Goal : Build a minimal AI-based recommender using Matrix Factorization/Neural Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdb41a1",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "## Data Source\n",
    "The dataset being used in this case is the Steam Video Game and Budle Data - User and Item data and item data from Professor Julian McAluley of the University of California San Diego\n",
    "\n",
    "### Metadata and Key Features\n",
    "#### Dataset 1 - user-item data\n",
    "Size : 527 MB  \n",
    "Items : 88310  \n",
    "Data Range :  \n",
    "Data Format : SteamID - Items{item_id, playtime_forever}  \n",
    "#### Dataset 2 - item data\n",
    "Size :  \n",
    "Items :  \n",
    "Data Range :   \n",
    "Data Format : ItemId - playtime_forever, (tags/genres/categories)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65e71b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  steam_id item_id  playtime  playtime_norm\n",
      "0        76561197970982479      10         6       0.000009\n",
      "1        76561197970982479      20         0       0.000000\n",
      "2        76561197970982479      30         7       0.000011\n",
      "3        76561197970982479      40         0       0.000000\n",
      "4        76561197970982479      50         0       0.000000\n",
      "...                    ...     ...       ...            ...\n",
      "5153203  76561198329548331  227940        43       0.000067\n",
      "5153204  76561198329548331  346330         0       0.000000\n",
      "5153205  76561198329548331  373330         0       0.000000\n",
      "5153206  76561198329548331  388490         3       0.000005\n",
      "5153207  76561198329548331  521570         4       0.000006\n",
      "\n",
      "[4294257 rows x 4 columns]\n",
      "           id                      name  \\\n",
      "0      761140       Lost Summoner Kitty   \n",
      "1      643980                 Ironbound   \n",
      "2      670290   Real Pool 3D - Poolians   \n",
      "3      767400                   弹炸人2222   \n",
      "4      773570             Log Challenge   \n",
      "...       ...                       ...   \n",
      "32130  773640            Colony On Mars   \n",
      "32131  733530  LOGistICAL: South Africa   \n",
      "32132  610660             Russian Roads   \n",
      "32133  658870       EXIT 2 - Directions   \n",
      "32134  681550               Maze Run VR   \n",
      "\n",
      "                                                    tags         price  \n",
      "0          [Strategy, Action, Indie, Casual, Simulation]          4.99  \n",
      "1      [Free to Play, Strategy, Indie, RPG, Card Game...  Free To Play  \n",
      "2      [Free to Play, Simulation, Sports, Casual, Ind...  Free to Play  \n",
      "3                            [Action, Adventure, Casual]          0.99  \n",
      "4                        [Action, Indie, Casual, Sports]          2.99  \n",
      "...                                                  ...           ...  \n",
      "32130              [Strategy, Indie, Casual, Simulation]          1.99  \n",
      "32131                          [Strategy, Indie, Casual]          4.99  \n",
      "32132                        [Indie, Simulation, Racing]          1.99  \n",
      "32133  [Indie, Casual, Puzzle, Singleplayer, Atmosphe...          4.99  \n",
      "32134  [Early Access, Adventure, Indie, Action, Simul...          4.99  \n",
      "\n",
      "[32135 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load user-item data\n",
    "with open('data/item_user_data.json', encoding='utf-8') as f:\n",
    "    user_data = json.load(f)\n",
    "\n",
    "# Load item data\n",
    "with open('data/item_data.json', encoding='utf-8') as f:\n",
    "    item_data = json.load(f)\n",
    "\n",
    "# Flatten the data to df\n",
    "rows = []\n",
    "for user in user_data:\n",
    "    for item in user['items']:\n",
    "        rows.append({\n",
    "            'steam_id': user['steam_id'],\n",
    "            'item_id': item['item_id'],\n",
    "            'playtime': item['playtime_forever']\n",
    "        })\n",
    "userItem_df = pd.DataFrame(rows)\n",
    "\n",
    "# Convert only relevant metadata to df\n",
    "rows = []\n",
    "for game in item_data:\n",
    "    rows.append({\n",
    "        'id' : game.get('id', None),\n",
    "        'name' : game.get('app_name', None),\n",
    "        'tags' : game.get('tags', None),\n",
    "        'price' : game.get('price', None)\n",
    "    })\n",
    "item_df = pd.DataFrame(rows)\n",
    "\n",
    "# Keep only games with metadata\n",
    "valid_games = set(item_df['id'])\n",
    "userItem_df = userItem_df[userItem_df['item_id'].isin(valid_games)]\n",
    "\n",
    "# Normalize playtime (0-1 scale)\n",
    "userItem_df['playtime_norm'] = (userItem_df['playtime'] - userItem_df['playtime'].min()) / \\\n",
    "(userItem_df['playtime'].max() - userItem_df['playtime'].min())\n",
    "\n",
    "print(userItem_df)\n",
    "print(item_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04521968",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e8a303",
   "metadata": {},
   "source": [
    "# Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b7436b",
   "metadata": {},
   "source": [
    "## Basline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f1e615",
   "metadata": {},
   "source": [
    "### Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8471ecff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Predicted playtime: 0.01\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     30\u001b[39m     predictions.append((game_id,pred.est))\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# get top 5\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m top_5 = \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTop 5 Recommended Games (CF) :\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m game_id, score \u001b[38;5;129;01min\u001b[39;00m top_5:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     30\u001b[39m     predictions.append((game_id,pred.est))\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# get top 5\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m top_5 = \u001b[38;5;28msorted\u001b[39m(predictions, key=\u001b[38;5;28;01mlambda\u001b[39;00m x: -\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTop 5 Recommended Games (CF) :\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m game_id, score \u001b[38;5;129;01min\u001b[39;00m top_5:\n",
      "\u001b[31mIndexError\u001b[39m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, Reader, KNNBasic\n",
    "\n",
    "# Prepare data\n",
    "reader = Reader(rating_scale=(0,1))\n",
    "data = Dataset.load_from_df(userItem_df[['steam_id', 'item_id', 'playtime_norm']], reader)\n",
    "\n",
    "# Train KNN model (Item-based CF)\n",
    "trainset = data.build_full_trainset()\n",
    "sim_opts = {'name': 'pearson', 'user_based': False}\n",
    "model_cf = KNNBasic(sim_options=sim_opts)\n",
    "model_cf.fit(trainset)\n",
    "\n",
    "# Save to disk\n",
    "with open('Models/cf_model(KNNBasic_pear).pkl', 'wb') as f:\n",
    "    pickle.dump(model_cf, f)\n",
    "\n",
    "# Get recommendations for a user\n",
    "pred = model_cf.predict(uid='76561197970982479', iid='730')\n",
    "print(f\"Predicted playtime: {pred.est:.2f}\")\n",
    "\n",
    "user_id = '76561197970982479'\n",
    "played_game = set(userItem_df[userItem_df['steam_id'] == user_id]['item_id'])\n",
    "all_games = set(userItem_df)\n",
    "unplayed_game = all_games-played_game\n",
    "\n",
    "# Player Predictions\n",
    "predictions = []\n",
    "for game_id in unplayed_game:\n",
    "    pred = model_cf.predict(uid=user_id, iid=game_id)\n",
    "    predictions.append((game_id,pred.est))\n",
    "\n",
    "# get top 5\n",
    "top_5 = sorted(predictions, key=lambda x: -x[1][:5])\n",
    "print(\"Top 5 Recommended Games (CF) :\")\n",
    "for game_id, score in top_5:\n",
    "    game_name = item_df[item_df['id'] == game_id]['title'].values[0]\n",
    "    print(f\"{game_name} (Predicted Playtime: {score:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d777734b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted playtime for 'Counter-Strike:Global Offensive' : 0.01\n",
      "Played: 232 | All: 32133 | Unplayed: 31901\n",
      "\n",
      "Top 5 Recommended Games (CF) :\n",
      "Pristine world (Predicted Playtime: 0.036610)\n",
      "SpiritSphere (Predicted Playtime: 0.036610)\n",
      "The Quivering (Predicted Playtime: 0.036610)\n",
      "Shrooms (Predicted Playtime: 0.018529)\n",
      "Cat President ~A More Purrfect Union~ (Predicted Playtime: 0.018398)\n"
     ]
    }
   ],
   "source": [
    "# Load KNN model (Item-based CF)\n",
    "with open('Models/cf_model(KNNBasic_pear).pkl', 'rb') as f:\n",
    "    model_cf = pickle.load(f)\n",
    "\n",
    "# Get recommendations for a user\n",
    "pred = model_cf.predict(uid='76561197970982479', iid='730')\n",
    "print(f\"Predicted playtime for 'Counter-Strike:Global Offensive' : {pred.est:.2f}\")\n",
    "\n",
    "user_id = '76561197970982479'\n",
    "played_game = set(userItem_df[userItem_df['steam_id'] == user_id]['item_id'])\n",
    "all_games = set(item_df['id'])\n",
    "unplayed_game = all_games-played_game\n",
    "print(f\"Played: {len(played_game)} | All: {len(all_games)} | Unplayed: {len(unplayed_game)}\\n\")\n",
    "\n",
    "\n",
    "# Player Predictions\n",
    "predictions = []\n",
    "for game_id in unplayed_game:\n",
    "    pred = model_cf.predict(uid=user_id, iid=game_id)\n",
    "    predictions.append((game_id,pred.est))\n",
    "\n",
    "# get top 5\n",
    "top_5 = sorted(predictions, key=lambda x: -x[1])[:5]\n",
    "print(\"Top 5 Recommended Games (CF) :\")\n",
    "for game_id, score in top_5:\n",
    "    game_name = item_df[item_df['id'] == game_id]['name'].values[0]\n",
    "    print(f\"{game_name} (Predicted Playtime: {score:4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e5bd07",
   "metadata": {},
   "source": [
    "### Content Based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7315ae6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'app_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programming\\Projects\\steam_data_project\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'app_name'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m np.save(\u001b[33m'\u001b[39m\u001b[33mModels/cosine_sim.npy\u001b[39m\u001b[33m'\u001b[39m, cos_sim)\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Get recommendations for a game\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m game_idx = item_df[\u001b[43mitem_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mapp_name\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m == \u001b[33m'\u001b[39m\u001b[33mCounter-Strike\u001b[39m\u001b[33m'\u001b[39m].index[\u001b[32m0\u001b[39m]\n\u001b[32m     24\u001b[39m sim_score = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(cos_sim[game_id]))\n\u001b[32m     25\u001b[39m sim_score = \u001b[38;5;28msorted\u001b[39m(sim_score, key=\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[32m1\u001b[39m], reverse=\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[32m1\u001b[39m:\u001b[32m6\u001b[39m] \u001b[38;5;66;03m#top 5\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programming\\Projects\\steam_data_project\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programming\\Projects\\steam_data_project\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'app_name'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "item_df['tags'] = item_df['tags'].fillna('').apply(\n",
    "    lambda x: ' '.join(x) if isinstance(x, list) else x\n",
    ")\n",
    "# Convert lists of tags into strings\n",
    "item_df['tags_str'] = item_df['tags'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
    "\n",
    "# Create TF-IDF matrix (weights)\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(item_df['tags_str'])\n",
    "\n",
    "# Save TF-IDF and matrix\n",
    "np.save('Models/tfidf_matrix.npy', tfidf_matrix.toarray())\n",
    "pickle.dump(tfidf, open('Models/tfidf_model.pkl', 'wb'))\n",
    "\n",
    "# Run and Save cosine matrix\n",
    "cos_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "np.save('Models/cosine_sim.npy', cos_sim)\n",
    "\n",
    "# Get recommendations for a game\n",
    "game_idx = item_df[item_df['app_name'] == 'Counter-Strike'].index[0]\n",
    "sim_score = list(enumerate(cos_sim[game_id]))\n",
    "sim_score = sorted(sim_score, key=lambda x: x[1], reverse=True)[1:6] #top 5\n",
    "rec_games = item_df.iloc[[i[0] for i in sim_score]]['app_name']\n",
    "print(rec_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75b53335",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load cosine simularity\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m cosine_sim = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mModels/cosine_sim.npy\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Get recommendations for a game\u001b[39;00m\n\u001b[32m      5\u001b[39m game_idx = item_df[item_df[\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m] == \u001b[33m'\u001b[39m\u001b[33mCounter-Strike\u001b[39m\u001b[33m'\u001b[39m].index[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programming\\Projects\\steam_data_project\\.venv\\Lib\\site-packages\\numpy\\lib\\npyio.py:456\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[39m\n\u001b[32m    453\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m.open_memmap(file, mode=mmap_mode,\n\u001b[32m    454\u001b[39m                                   max_header_size=max_header_size)\n\u001b[32m    455\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    460\u001b[39m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[32m    461\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programming\\Projects\\steam_data_project\\.venv\\Lib\\site-packages\\numpy\\lib\\format.py:809\u001b[39m, in \u001b[36mread_array\u001b[39m\u001b[34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[39m\n\u001b[32m    806\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m isfileobj(fp):\n\u001b[32m    808\u001b[39m         \u001b[38;5;66;03m# We can use the fast fromfile() function.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m809\u001b[39m         array = \u001b[43mnumpy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    810\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    811\u001b[39m         \u001b[38;5;66;03m# This is not a real file. We have to read it the\u001b[39;00m\n\u001b[32m    812\u001b[39m         \u001b[38;5;66;03m# memory-intensive way.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    820\u001b[39m         \u001b[38;5;66;03m# not correctly instantiate zero-width string dtypes; see\u001b[39;00m\n\u001b[32m    821\u001b[39m         \u001b[38;5;66;03m# https://github.com/numpy/numpy/pull/6430\u001b[39;00m\n\u001b[32m    822\u001b[39m         array = numpy.ndarray(count, dtype=dtype)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Load cosine simularity\n",
    "cosine_sim = np.load('Models/cosine_sim.npy')\n",
    "\n",
    "# Get recommendations for a game\n",
    "game_idx = item_df[item_df['name'] == 'Counter-Strike'].index[0]\n",
    "sim_score = list(enumerate(cos_sim[game_id]))\n",
    "sim_score = sorted(sim_score, key=lambda x: x[1], reverse=True)[1:6] #top 5\n",
    "rec_games = item_df.iloc[[i[0] for i in sim_score]]['name']\n",
    "print(rec_games)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8667eb7b",
   "metadata": {},
   "source": [
    "## AI-Based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7e3bc72",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m     42\u001b[39m         optimzer.zero_grad()\n\u001b[32m     43\u001b[39m         loss.backward()\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m         \u001b[43moptimzer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m torch.save(model.state_dict(), \u001b[33m'\u001b[39m\u001b[33mncf_model.pth\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programming\\Projects\\steam_data_project\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:485\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    481\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    482\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    483\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    488\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programming\\Projects\\steam_data_project\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:79\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     78\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     81\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programming\\Projects\\steam_data_project\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py:246\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    234\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    236\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    237\u001b[39m         group,\n\u001b[32m    238\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    243\u001b[39m         state_steps,\n\u001b[32m    244\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programming\\Projects\\steam_data_project\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:147\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programming\\Projects\\steam_data_project\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py:933\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    931\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m933\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Programming\\Projects\\steam_data_project\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py:416\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    413\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    414\u001b[39m             grad = grad.add(param, alpha=weight_decay)\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    417\u001b[39m     grad = torch.view_as_real(grad)\n\u001b[32m    418\u001b[39m     exp_avg = torch.view_as_real(exp_avg)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class NCF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, emb_size=32):\n",
    "        super().__init__()\n",
    "        self.user_embed = nn.Embedding(num_users, emb_size)\n",
    "        self.item_embed = nn.Embedding(num_items, emb_size)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(emb_size * 2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, user, item):\n",
    "        u = self.user_embed(user)\n",
    "        i = self.item_embed(item)\n",
    "        x = torch.cat([u, i], dim=1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# preare data\n",
    "user_ids = userItem_df['steam_id'].astype('category').cat.codes.values\n",
    "item_ids = userItem_df['item_id'].astype('category').cat.codes.values\n",
    "labels = userItem_df['playtime_norm'].values\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(\n",
    "    torch.tensor(user_ids, dtype=torch.long),\n",
    "    torch.tensor(item_ids, dtype=torch.long),\n",
    "    torch.tensor(labels, dtype=torch.float)\n",
    ")\n",
    "\n",
    "# training\n",
    "model = NCF(num_users=max(user_ids)+1, num_items=max(item_ids)+1)\n",
    "optimzer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "for epoch in range(10):\n",
    "    for user, item, label in torch.utils.data.DataLoader(train_data, batch_size=64):\n",
    "        pred = model(user, item)\n",
    "        loss = loss_fn(pred.squeeze(), label)\n",
    "        optimzer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimzer.step()\n",
    "        \n",
    "torch.save(model.state_dict(), 'ncf_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daf8e0d",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf23b8c6",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f65419",
   "metadata": {},
   "source": [
    "## AI-Based Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918c5c9b",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ad0b7d",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "## Summary\n",
    "## Limitations\n",
    "## Future"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
